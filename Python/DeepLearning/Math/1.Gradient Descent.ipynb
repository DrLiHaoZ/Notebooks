{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Weight = 0.46, Bias = 0.14, Loss = 53.0\n",
      "Epoch 2: Weight = 0.8196000000000001, Bias = 0.2496, Loss = 32.401999999999994\n",
      "Epoch 3: Weight = 1.1007040000000001, Bias = 0.335432, Loss = 19.811174719999997\n",
      "Epoch 4: Weight = 1.3204372800000002, Bias = 0.40268112, Loss = 12.114843647551998\n",
      "Epoch 5: Weight = 1.4921889568000002, Bias = 0.4554012608, Loss = 7.410338605343355\n",
      "Epoch 6: Weight = 1.6264270897920001, Bias = 0.49676189817599997, Loss = 4.5346278659682895\n",
      "Epoch 7: Weight = 1.73133595794304, Bias = 0.52924103482496, Loss = 2.7767925128958155\n",
      "Epoch 8: Weight = 1.8133143042649345, Bias = 0.5547760566518783, Loss = 1.7022737167473816\n",
      "Epoch 9: Weight = 1.8773648800128349, Bias = 0.5748816772629447, Loss = 1.045441499382427\n",
      "Epoch 10: Weight = 1.9273990033744912, Bias = 0.5907421509169157, Loss = 0.6439259339750382\n",
      "Epoch 11: Weight = 1.966474673644578, Bias = 0.6032833676961079, Loss = 0.39847620046774823\n",
      "Epoch 12: Weight = 1.996982736853896, Bias = 0.6132292199235111, Loss = 0.24842388883058844\n",
      "Epoch 13: Weight = 2.020792436287706, Bias = 0.6211456713138072, Loss = 0.15668461041419196\n",
      "Epoch 14: Weight = 2.0393652087513363, Bias = 0.6274752117102687, Loss = 0.10059002948287307\n",
      "Epoch 15: Weight = 2.053843654298453, Bias = 0.6325637949509831, Loss = 0.06628381815423609\n",
      "Epoch 16: Weight = 2.0651210957417034, Bias = 0.6366818997940563, Loss = 0.04529610785456799\n",
      "Epoch 17: Weight = 2.0738959626057194, Bias = 0.640040996053673, Loss = 0.032449576314026875\n",
      "Epoch 18: Weight = 2.0807143103213552, Bias = 0.6428064183762564, Loss = 0.024579514845031947\n",
      "Epoch 19: Weight = 2.086003063154509, Bias = 0.6451074313894499, Loss = 0.01975145210786725\n",
      "Epoch 20: Weight = 2.09009600464024, Bias = 0.6470450989723904, Loss = 0.016782916026904307\n",
      "Epoch 21: Weight = 2.0932540977738485, Bias = 0.6486984367145282, Loss = 0.014951104276077293\n",
      "Epoch 22: Weight = 2.095681372016207, Bias = 0.6501292221138067, Loss = 0.013814193898586053\n",
      "Epoch 23: Weight = 2.0975373442861374, Bias = 0.6513857553505582, Loss = 0.013102114388556373\n",
      "Epoch 24: Weight = 2.0989467301078766, Bias = 0.6525057995863788, Loss = 0.012649781255879816\n",
      "Epoch 25: Weight = 2.1000070361111187, Bias = 0.6535188797881786, Loss = 0.012356284137237905\n",
      "Epoch 26: Weight = 2.1007944961016043, Bias = 0.6544480800257478, Loss = 0.012159939975477757\n",
      "Epoch 27: Weight = 2.1013687120797386, Bias = 0.6553114486591366, Loss = 0.012023043937175343\n",
      "Epoch 28: Weight = 2.1017762827442428, Bias = 0.6561230969611695, Loss = 0.011922548204187313\n",
      "Epoch 29: Weight = 2.102053640377724, Bias = 0.6568940580572916, Loss = 0.01184436425857023\n",
      "Epoch 30: Weight = 2.102229268818742, Bias = 0.6576329584734824, Loss = 0.011779880076962889\n",
      "Epoch 31: Weight = 2.1023254375465847, Bias = 0.6583465431748882, Loss = 0.011723831218415687\n",
      "Epoch 32: Weight = 2.1023595574467744, Bias = 0.6590400860585953, Loss = 0.011672999497952103\n",
      "Epoch 33: Weight = 2.1023452407939036, Bias = 0.6597177108906169, Loss = 0.011625417533130447\n",
      "Epoch 34: Weight = 2.102293129981686, Bias = 0.6603826422251704, Loss = 0.0115798825123396\n",
      "Epoch 35: Weight = 2.1022115454518384, Bias = 0.6610374015817658, Loss = 0.011535658979073342\n",
      "Epoch 36: Weight = 2.102106992266565, Bias = 0.6616839608230202, Loss = 0.011492297154781846\n",
      "Epoch 37: Weight = 2.101984556163871, Bias = 0.6623238620705659, Loss = 0.011449521886250643\n",
      "Epoch 38: Weight = 2.1018482132068628, Bias = 0.6629583114593224, Loss = 0.011407164763175319\n",
      "Epoch 39: Weight = 2.101701071877931, Bias = 0.6635882524377241, Loss = 0.011365122624105096\n",
      "Epoch 40: Weight = 2.1015455623560815, Bias = 0.6642144230762937, Loss = 0.011323332192636995\n",
      "Epoch 41: Weight = 2.1013835845002875, Bias = 0.664837400873403, Loss = 0.011281754573440545\n",
      "Epoch 42: Weight = 2.101216623547826, Bias = 0.6654576377859177, Loss = 0.011240365775241245\n",
      "Epoch 43: Weight = 2.1010458405711057, Bias = 0.6660754876173298, Loss = 0.011199150917862262\n",
      "Epoch 44: Weight = 2.1008721431998447, Bias = 0.6666912274307168, Loss = 0.01115810069119608\n",
      "Epoch 45: Weight = 2.100696240914033, Bias = 0.6673050742901119, Loss = 0.011117209190702604\n",
      "Epoch 46: Weight = 2.1005186882738194, Bias = 0.6679171983494676, Loss = 0.01107647259432255\n",
      "Epoch 47: Weight = 2.1003399187180873, Bias = 0.6685277330860491, Loss = 0.011035888353720831\n",
      "Epoch 48: Weight = 2.100160270989307, Bias = 0.6691367833012428, Loss = 0.01099545469992142\n",
      "Epoch 49: Weight = 2.099980009793371, Bias = 0.6697444313758596, Loss = 0.010955170341114958\n",
      "Epoch 50: Weight = 2.0997993419521452, Bias = 0.6703507421607402, Loss = 0.010915034277938752\n",
      "Epoch 51: Weight = 2.0996184290320716, Bias = 0.6709557668003967, Loss = 0.01087504569055993\n",
      "Epoch 52: Weight = 2.0994373972176334, Bias = 0.6715595457224645, Loss = 0.010835203869651183\n",
      "Epoch 53: Weight = 2.099256345030759, Bias = 0.6721621109749571, Loss = 0.010795508174196385\n",
      "Epoch 54: Weight = 2.09907534936611, Bias = 0.6727634880536124, Loss = 0.010755958005695072\n",
      "Epoch 55: Weight = 2.0988944702096712, Bias = 0.6733636973305736, Loss = 0.010716552792392382\n",
      "Epoch 56: Weight = 2.0987137543279024, Bias = 0.6739627551713818, Loss = 0.010677291979636152\n",
      "Epoch 57: Weight = 2.098533238152039, Bias = 0.6745606748082801, Loss = 0.010638175023980656\n",
      "Epoch 58: Weight = 2.0983529500331346, Bias = 0.6751574670229922, Loss = 0.010599201389578754\n",
      "Epoch 59: Weight = 2.0981729120051282, Bias = 0.6757531406805443, Loss = 0.010560370545973887\n",
      "Epoch 60: Weight = 2.0979931411632697, Bias = 0.6763477031466257, Loss = 0.010521681966748783\n",
      "Epoch 61: Weight = 2.097813650741818, Bias = 0.6769411606138971, Loss = 0.010483135128694598\n",
      "Epoch 62: Weight = 2.0976344509566207, Bias = 0.6775335183571101, Loss = 0.010444729511303314\n",
      "Epoch 63: Weight = 2.09745554966387, Bias = 0.6781247809325706, Loss = 0.010406464596451373\n",
      "Epoch 64: Weight = 2.097276952875142, Bias = 0.678714952334087, Loss = 0.01036833986820658\n",
      "Epoch 65: Weight = 2.0970986651600683, Bias = 0.6793040361148968, Loss = 0.010330354812705254\n",
      "Epoch 66: Weight = 2.096920689961161, Bias = 0.6798920354829947, Loss = 0.010292508918076008\n",
      "Epoch 67: Weight = 2.096743029839949, Bias = 0.6804789533756651, Loss = 0.010254801674389274\n",
      "Epoch 68: Weight = 2.0965656866694196, Bias = 0.6810647925177549, Loss = 0.010217232573624405\n",
      "Epoch 69: Weight = 2.0963886617844705, Bias = 0.6816495554672346, Loss = 0.010179801109647169\n",
      "Epoch 70: Weight = 2.0962119560995425, Bias = 0.6822332446508217, Loss = 0.010142506778192503\n",
      "Epoch 71: Weight = 2.0960355702005846, Bias = 0.6828158623918327, Loss = 0.010105349076852314\n",
      "Epoch 72: Weight = 2.095859504416958, Bias = 0.6833974109319609, Loss = 0.010068327505064738\n",
      "Epoch 73: Weight = 2.0956837588776485, Bias = 0.6839778924483042, Loss = 0.010031441564105407\n",
      "Epoch 74: Weight = 2.0955083335552205, Bias = 0.6845573090666792, Loss = 0.009994690757078796\n",
      "Epoch 75: Weight = 2.0953332283001758, Bias = 0.6851356628720324, Loss = 0.009958074588911509\n",
      "Epoch 76: Weight = 2.0951584428678185, Bias = 0.6857129559165812, Loss = 0.009921592566344435\n",
      "Epoch 77: Weight = 2.0949839769392598, Bias = 0.6862891902261805, Loss = 0.009885244197926298\n",
      "Epoch 78: Weight = 2.094809830137837, Bias = 0.6868643678053014, Loss = 0.009849028994005918\n",
      "Epoch 79: Weight = 2.0946360020419514, Bias = 0.6874384906409251, Loss = 0.009812946466727071\n",
      "Epoch 80: Weight = 2.0944624921951056, Bias = 0.6880115607055896, Loss = 0.0097769961300204\n",
      "Epoch 81: Weight = 2.0942893001137493, Bias = 0.6885835799597714, Loss = 0.009741177499597332\n",
      "Epoch 82: Weight = 2.094116425293413, Bias = 0.689154550353751, Loss = 0.009705490092943837\n",
      "Epoch 83: Weight = 2.0939438672135053, Bias = 0.6897244738290712, Loss = 0.009669933429313153\n",
      "Epoch 84: Weight = 2.09377162534106, Bias = 0.6902933523196795, Loss = 0.009634507029720605\n",
      "Epoch 85: Weight = 2.093599699133667, Bias = 0.6908611877528222, Loss = 0.009599210416935323\n",
      "Epoch 86: Weight = 2.0934280880417644, Bias = 0.6914279820497458, Loss = 0.009564043115475662\n",
      "Epoch 87: Weight = 2.0932567915104268, Bias = 0.691993737126245, Loss = 0.009529004651601291\n",
      "Epoch 88: Weight = 2.0930858089807667, Bias = 0.6925584548930945, Loss = 0.009494094553307821\n",
      "Epoch 89: Weight = 2.0929151398910277, Bias = 0.6931221372563866, Loss = 0.009459312350320154\n",
      "Epoch 90: Weight = 2.092744783677439, Bias = 0.6936847861177972, Loss = 0.009424657574085882\n",
      "Epoch 91: Weight = 2.0925747397748835, Bias = 0.6942464033747948, Loss = 0.009390129757769133\n",
      "Epoch 92: Weight = 2.092405007617419, Bias = 0.6948069909208059, Loss = 0.00935572843624426\n",
      "Epoch 93: Weight = 2.092235586638687, Bias = 0.6953665506453446, Loss = 0.009321453146090015\n",
      "Epoch 94: Weight = 2.0920664762722287, Bias = 0.6959250844341165, Loss = 0.00928730342558245\n",
      "Epoch 95: Weight = 2.0918976759517363, Bias = 0.6964825941691004, Loss = 0.009253278814689474\n",
      "Epoch 96: Weight = 2.091729185111243, Bias = 0.6970390817286142, Loss = 0.009219378855064502\n",
      "Epoch 97: Weight = 2.091561003185278, Bias = 0.6975945489873673, Loss = 0.009185603090039435\n",
      "Epoch 98: Weight = 2.09139312960898, Bias = 0.6981489978165033, Loss = 0.00915195106462018\n",
      "Epoch 99: Weight = 2.091225563818194, Bias = 0.6987024300836344, Loss = 0.009118422325478603\n",
      "Epoch 100: Weight = 2.091058305249537, Bias = 0.69925484765287, Loss = 0.00908501642094795\n",
      "Final Weight: 2.091058305249537\n",
      "Final Bias: 0.69925484765287\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 训练数据\n",
    "X = np.array([[2], [4]])\n",
    "y = np.array([[5], [9]])\n",
    "\n",
    "# 初始化权重和偏置\n",
    "w = np.array([[0]])\n",
    "b = 0\n",
    "\n",
    "# 超参数设置\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# 批量梯度下降训练\n",
    "for epoch in range(epochs):\n",
    "    # 前向传播\n",
    "    y_pred = np.dot(X, w) + b\n",
    "\n",
    "    # 计算损失函数（均方误差）\n",
    "    loss = np.mean((y_pred - y) ** 2)\n",
    "\n",
    "    # 计算梯度\n",
    "    dw = 2 * np.mean((y_pred - y) * X, axis=0, keepdims=True)\n",
    "    db = 2 * np.mean(y_pred - y)\n",
    "\n",
    "    # 更新权重和偏置\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    # 打印当前更新的权重和偏置\n",
    "    print(f'Epoch {epoch + 1}: Weight = {w[0][0]}, Bias = {b}, Loss = {loss}')\n",
    "\n",
    "# 打印最终的权重和偏置\n",
    "print(f'Final Weight: {w[0][0]}')\n",
    "print(f'Final Bias: {b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
