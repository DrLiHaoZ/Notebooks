{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.constant & ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor with tf.constant\n",
    "scalar = tf.constant(7)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimension of a scalar tensor using the ndim\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector using tf.constant\n",
    "vector = tf.constant([1,2,3])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimension of our vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix using tf.constant\n",
    "matrix = tf.constant([[1,2,3],[4,5,6]],dtype=tf.float16)\n",
    "print(matrix)\n",
    "print(\"\\n the ndim of your tensor is {}.\".format(matrix.ndim))\n",
    "print(\"\\n the shape of your tensor is {}.\".format(matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor & ndarray(numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to recap, ndim is actually the length of the shape\n",
    "# you should also notice that np.array similarly has attribute of ndim and shape\n",
    "array = np.arange(start = 1, stop = 10, step = 1)\n",
    "print(array,'\\n')\n",
    "print('the shape of array:' ,array.shape)\n",
    "print('the dimension of array:',array.ndim)\n",
    "# let's reshape the ndarray\n",
    "array_reshaped = np.reshape(array,(3,3)) #(3,3) is the new shape of the array\n",
    "print('the shape of the reshaped array is {}.'.format(array_reshaped.shape))\n",
    "print('the ndim of the reshaped array is {}.'.format(array_reshaped.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use tensor.numpy() to convert tensor to ndarray\n",
    "tensor_to_ndarray = tf.constant([[1,2,3],[4,5,6]])\n",
    "tensor_to_ndarray.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Variable & assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.variable is the changable version of tensor\n",
    "changeable_tensor = tf.Variable([[1,2],[3,4]])\n",
    "unchangeable_tensor = tf.constant([1,2])\n",
    "\n",
    "# first the tensor can be indexed by [][]\n",
    "print(changeable_tensor)\n",
    "print('the first element of changeable tensor is :{}'.format(changeable_tensor[0][0]))\n",
    "print('the last element of changeable tensor is :{}'.format(changeable_tensor[1][1]))\n",
    "\n",
    "# the item-wise assign fail , but I can reassin the whole thing\n",
    "changeable_tensor.assign(np.array([[3,4],[5,6]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two but the same tensor /psudo random number\n",
    "\n",
    "## use the same generator twice will cause different tensor \n",
    "generator = tf.random.Generator.from_seed(12)\n",
    "random1 = generator.normal(shape = (3,3))\n",
    "random2 = generator.normal(shape = (3,3))\n",
    "print(\"random1 tensor is :{}\".format(random1))\n",
    "print(\"random2 tensor is :{}\".format(random2))\n",
    "print(random1 == random2)  # this operation will get the bool matrix\n",
    "\n",
    "# use the same but different piece of generator will generate same entity\n",
    "generator3 = tf.random.Generator.from_seed(12)\n",
    "generator4 = tf.random.Generator.from_seed(12)\n",
    "random3 = generator3.normal(shape=(3, 3))\n",
    "random4 = generator4.normal(shape=(3, 3))\n",
    "print(\"random3 tensor is :{}\".format(random3))\n",
    "print(\"random4 tensor is :{}\".format(random4))\n",
    "print(random3 == random4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle & first dimension\n",
    "## understand the order of shape(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_shuffle = tf.constant([\n",
    "                                [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], \n",
    "                                [[10, 20, 30], [40, 50, 60], [70, 80, 90], [100, 110, 120]],\n",
    "                                [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "                                ])\n",
    "print(\"the shape of tensor is:\",tensor_to_shuffle.shape)\n",
    "print(\"the ndim of tensor is :\",tensor_to_shuffle.ndim)\n",
    "print(\"tensor_to_shuffle:\",tensor_to_shuffle)\n",
    "\n",
    "tensor_shuffled = tf.random.shuffle(tensor_to_shuffle)\n",
    "print(\"tensor_shuffled:\",tensor_shuffled)\n",
    "\n",
    "# please note that shuffle function will only shuffle the first dimension of the tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other ways to create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_onses = tf.ones(shape = (4,4))\n",
    "print(tensor_onses)\n",
    "tensor_zeros = tf.zeros(shape = (4,4))\n",
    "print(tensor_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# manipulate the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concert a tensor from numpy array, and reshepe it!\n",
    "np_array = np.arange(0,10,dtype=np.int32)\n",
    "tensor = tf.constant(np_array)\n",
    "tensor_shape1 = tf.constant(np_array,shape = (2,5))\n",
    "print(\"tensor_shape1:\",tensor_shape1)\n",
    "# now index the tensor, every first dimension of with last element of the last dimension\n",
    "print(\"slicing the tensor is :\",tensor_shape1[:,-1])\n",
    "\n",
    "# now add an extra dimension to our 2-dimension tensor\n",
    "tensor_shape2 = tensor_shape1[:,:,tf.newaxis]\n",
    "print(\"our tensor with extra  dimension is :\",tensor_shape2)\n",
    "print(\"it's shape is :\",tensor_shape2.shape)\n",
    "\n",
    "# here is another annotation to add another \n",
    "tensor_shape3 = tensor_shape1[..., tf.newaxis] # the annotation of ... stand for every dimension before\n",
    "print(\"our tensor with extra  dimension is :\", tensor_shape3)\n",
    "print(\"it's shape is :\", tensor_shape3.shape)\n",
    "\n",
    "\n",
    "tensor_shape3 = tensor_shape1[:,tf.newaxis,:]\n",
    "print(\"our tensor with extra  dimension is :\",tensor_shape3)\n",
    "print(\"it's shape is :\",tensor_shape3.shape)\n",
    "\n",
    "# alternative to tf.newaxis: tf.expand_dims()\n",
    "\n",
    "tensor_shape4 = tf.expand_dims(tensor,axis = -1) # axis = -1 means to expand a new dimension in the last dimension(axis)\n",
    "print(\"expand dimension using tf.expand_dims():\",tensor_shape4)\n",
    "print(\"thes shape of new tensor:\",tensor_shape4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tensor1 dot(@) tensor2 =  tf.Tensor(\n",
      "[[ 7 10]\n",
      " [15 22]], shape=(2, 2), dtype=int32)\n",
      "tensor1 * tensor2 =  tf.Tensor(\n",
      "[[ 1  4]\n",
      " [ 9 16]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# martix multiplication\n",
    "tensor1 = tf.constant([[1,2],[3,4]])\n",
    "tensor2 = tf.constant([[1, 2], [3, 4]])\n",
    "tensor3 = tf.constant(np.identity(3))\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "\n",
    "print(\"tensor1 dot(@) tensor2 = \",tensor1 @ tensor2)\n",
    "print(\"tensor1 * tensor2 = \", tensor1 * tensor2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([2,3,4])\n",
    "print(a * b) # this type of multiplication is element-wise\n",
    "print(np.dot(a * b)) # this is the dot pr"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1513c558104143c9342deba70e5828cd4c39a134479ea9220253fbe85c0c4494"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
