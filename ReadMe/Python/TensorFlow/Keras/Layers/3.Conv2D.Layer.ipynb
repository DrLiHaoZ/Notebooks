{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kernel = tf.constant(np.array([\n",
    "    [0,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,0]\n",
    "]), dtype = tf.float32)\n",
    "\n",
    "my_kernel = tf.reshape(my_kernel,shape = (1,3,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 6, 1), dtype=float32, numpy=\n",
       "array([[[[8.],\n",
       "         [5.],\n",
       "         [5.],\n",
       "         [0.],\n",
       "         [8.],\n",
       "         [6.]],\n",
       "\n",
       "        [[8.],\n",
       "         [3.],\n",
       "         [8.],\n",
       "         [9.],\n",
       "         [2.],\n",
       "         [9.]],\n",
       "\n",
       "        [[5.],\n",
       "         [9.],\n",
       "         [5.],\n",
       "         [1.],\n",
       "         [6.],\n",
       "         [4.]],\n",
       "\n",
       "        [[3.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [6.],\n",
       "         [2.],\n",
       "         [8.]],\n",
       "\n",
       "        [[7.],\n",
       "         [5.],\n",
       "         [3.],\n",
       "         [2.],\n",
       "         [6.],\n",
       "         [9.]],\n",
       "\n",
       "        [[4.],\n",
       "         [5.],\n",
       "         [9.],\n",
       "         [2.],\n",
       "         [6.],\n",
       "         [8.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = tf.constant(np.random.randint(low = 0, high = 10, size = 36),shape = (6,6),dtype = tf.float32)\n",
    "plt.imshow(image)\n",
    "image = tf.reshape(tensor = image,shape = (1,6,6,1))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:33:14.074218: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:675 : INVALID_ARGUMENT: input depth must be evenly divisible by filter depth: 1 vs 3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "input depth must be evenly divisible by filter depth: 1 vs 3 [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb#ch0000003?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m image, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb#ch0000003?line=1'>2</a>\u001b[0m              filters \u001b[39m=\u001b[39;49m my_kernel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb#ch0000003?line=2'>3</a>\u001b[0m              strides \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb#ch0000003?line=3'>4</a>\u001b[0m              padding \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mVALID\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lihao/Desktop/MindmapDXY/ReadMe/Python/NLP/Keras/Layers/3.Conv2D.Layer.ipynb#ch0000003?line=4'>5</a>\u001b[0m              )\n",
      "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7107\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7104'>7105</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7105'>7106</a>\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///~/anaconda3/envs/learn/lib/python3.9/site-packages/tensorflow/python/framework/ops.py?line=7106'>7107</a>\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input depth must be evenly divisible by filter depth: 1 vs 3 [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "tf.nn.conv2d(input = image, \n",
    "             filters = my_kernel,\n",
    "             strides = 3,\n",
    "             padding = \"VALID\"\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc00d93549840f82d8acc721d5c7e03f45705ab4bd4c4e913c35136c2ef2ccbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('learn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
